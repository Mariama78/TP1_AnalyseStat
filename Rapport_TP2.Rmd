---
title: "Rapport Travail Pratique N°2"
author: "Emma BRAZ DA COSTA-RAMOS (BRAE21560400) <br>
Gautier BRÈRE (BRIG01040400)<br>
Edward CARAMANOS (CARE17080300) <br>
Mariama CIRÉ CAMARA (CAMM06609200) <br>
Yoann CORGNET (CORY14010400)"
date: "2025-04-22"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, error=FALSE) 
```

```{r, load-libraries, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}
library(skimr)
library(tidyverse)
library(rsample)
library(yardstick)
library(plotly)
library(dplyr)
```

## I- Introduction

Ce travail pratique est la suite du travail réalisé pendant la première moité de ce trimestre.

Dans un premier temps, nous allons formuler plusieurs hypothèses statistiques à tester sur les données issues du fichier "movies.csv" du site TMDB. Les analyses porteront principalement sur les variables budget, revenue, runtime, popularity, vote_average, vote_count, original_language, et genres.

Puis nous testerons d'autres modèles afin de prédire le revenu des films, en comparant ces résultats aux régressions linéaires faites dans le TP1.

*Objectif 1* : Explorer et valider des relations statistiques entre différentes caractéristiques des films, afin de mieux comprendre les facteurs de succès cinématographique.

*Objectif 2* : Rechercher un modèle de donnée performant pour prédire le revenu d'un film.

## II- Importation et nettoyage des données

Ce dataset contient les métadonnées de plus de 700 000 films répertoriés dans l’ensemble de données TMDB. Il est mis à jour quotidiennement pour garantir la mise à jour de l’ensemble de données sur les films. Les points de données comprennent les acteurs, l’équipe, les mots-clés de l’intrigue, le budget, les revenus, les affiches, les dates de sortie, les langues, les sociétés de production, les pays, le nombre de votes TMDB et les moyennes des votes, les critiques, les recommandations.

**Description des variables**

- id : Identifiant unique pour chaque film.
- title : Titre du film.
- genres : Genres du film, combinés dans une seule chaîne de caractères (ex : Action-Comedy).
- original_language : Langue originale du film.
- overview : Résumé ou description du film.
- popularity : Score de popularité du film.
- production_companies : Compagnies de production associées au film, listées dans une chaîne de caractères.
- release_date : Date de sortie du film.
- budget : Budget du film en dollars.
- revenue : Revenu généré par le film en dollars.
- runtime : Durée du film en minutes.
- status : Statut du film (ex : Released).
- tagline : Slogan du film.
- vote_average : Moyenne des votes pour le film.
- vote_count : Nombre total de votes reçus par le film.
- credits : Principaux acteurs et membres de l'équipe du film.
- keywords : Mots-clés associés au film, listés dans une chaîne de caractères.
- poster_path : Chemin vers l'image de l'affiche du film.
- backdrop_path : Chemin vers l'image de fond du film.
- recommendations : Identifiants de films recommandés basés sur ce film, listés dans une chaîne de caractères.

### A- Importation des données

```{r, load-data}
movies <- read.csv("data/movies.csv")
```

Le dataset compte `r nrow(movies)` entrées pour `r ncol(movies)` variables.

### B- Supression des variables non pertinentes

Voici le résumé des variables du dataset:

```{r variables-details}
skim(movies)
```

Pour notre analyse et pour réduire la taille du dataset, nous supprimerons les variables que nous n'utiliserons pas pour notre analyse :

```{r remove-unused-variables}
clean_movies <- select(movies, -id, -overview, -tagline, -credits, -keywords, -poster_path, -backdrop_path, -recommendations)
head(clean_movies)
```

### C- Nettoyage des variables

- **Variable `release_date` :**

Regardons la distribution des dates de sorties :

```{r release_date-distribution, warning=FALSE}
clean_movies$release_date <- as.Date(clean_movies$release_date, format="%Y-%m-%d")

ggplot(clean_movies, aes(x = release_date)) +
  geom_histogram(binwidth = 5, fill="steelblue", color="black") +
  labs(title="Distribution des films par année de sortie", x="Date", y="Nombre de films") +
  theme_minimal()
```

On peut observer deux choses :  
1- Les films ont tendance à sortir à des dates précises durant l'année, nous nous retrouvons donc avec des pics.  
Pour notre analyse, nous regarderons donc l'année, le mois et la décennie de sortie, et non la date exacte:

```{r clean-release_date}
# Suppression des dates maquantes
clean_movies <- clean_movies %>% filter(!is.na(release_date))
# Ajout des variables
clean_movies <- clean_movies %>%
  mutate(
    release_year = as.numeric(format(release_date, "%Y")),
    release_mounth = as.numeric(format(release_date, "%m")),
    release_decate = as.numeric(format(release_date, "%Y")) %/% 10 * 10
  )

head(clean_movies %>% select(title, release_date, release_year, release_mounth, release_decate))
```

2- Nous observons que certains films sont sortis après 2025, regardons desquels il s'agit :

```{r movies-after-2025}
clean_movies %>% filter(release_date > "2025-01-22") %>% select(title, status, release_date) %>% head()
```

Ce sont donc des films qui ne sont pas encore sortis et dont la date est une prévision.   
Pour notre analyse, nous nous concentrerons uniquement sur les films sortis:

```{r released-movies, warning=FALSE}
clean_movies <- clean_movies %>% filter(status == "Released")

ggplot(clean_movies, aes(x = release_year)) +
  geom_histogram(binwidth = 5, fill="steelblue", color="black") +
  labs(title="Distribution des films par année de sortie", x="Date", y="Nombre de films") +
  theme_minimal()
```

- **Variable `runtime` :**

Après une observation des durées de films, nous remarquons plusieurs choses intéressantes :

```{r runtime}
clean_movies %>% 
  filter(!is.na(runtime)) %>%
  arrange(desc(runtime)) %>%
  head(10) %>%
  select(title, runtime)
```

Nous remarquons deux films "troll" qui durent plus de 96 ans chacun, ainsi que des films expérimentaux comme "Logistics" qui dure 35 jours. Pour notre analyse, nous ne tiendrons donc pas compte de ces films et nous contenterons des films de moins de 4h.

```{r runtime-hist}
clean_movies = clean_movies %>% 
  filter(runtime < 240) # Limitons-nous à des films de moins de 4h

ggplot(clean_movies, aes(runtime)) +
  geom_bar() +
  labs(title="Distribution des durées de films", x="Durée", y="Nombre de films") +
  theme_minimal()
```

L'histogramme de la durée des films de moins de 4h nous permet d'obtenir plusieurs informations :  
1. On observe une distinction entre les courts métrages (10 min en moyenne) et les longs métrages (1h30 en moyenne).  
2. Il existe beaucoup de films dont la durée est de zéro: `r clean_movies %>% filter(runtime == 0) %>% count()` au total (soit `r (100 * count(filter(clean_movies, runtime == 0)) / nrow(clean_movies)) %>% round(2)` %).

Afin de ne pas biaiser nos modèles sur des valeurs manquantes/nulles, nous ne tiendrons pas compte des films dont la durée n'est pas renseignée:

```{r remove-runtime-0}
clean_movies <- clean_movies %>% filter(!is.na(runtime) & runtime > 0)

ggplot(clean_movies, aes(runtime)) +
  geom_bar() +
  labs(title="Distribution des durées de films", x="Durée", y="Nombre de films") +
  theme_minimal()
```

- **Variable `genres` :**

Le genre des films est stocké sous la forme "genre_principale[-genre_secondaire]...", ce qui fait que nous nous retrouvons avec un total de `r length(distinct(movies, genres)$genres)` genres.

Nous allons séparer ces genres, puis compter le nombre de films par genre.


```{r clean-genres}
clean_movies <- clean_movies %>%
  mutate(genres = gsub("-.*", "", genres))

head(clean_movies%>% select(title,genres))

```


Nous nous retrouvons donc avec `r length(distinct(clean_movies, genres)$genres)` genres.

Top 3 des genres principaux :

```{r first-gender-details}
clean_movies %>% 
  filter(!is.na(genres) & genres != "") %>% 
  count(genres) %>% 
  arrange(desc(n)) %>% 
  head(n = 3)
```


- **Variables `vote_count` et `vote_average` :**

```{r vote_average-hist}
ggplot(clean_movies, aes(x = vote_average)) +
  geom_histogram(binwidth = 0.5, fill="steelblue", color="black") +
  labs(
    title = "Distribution des notes moyennes des films",
     x = "Note moyenne",
     y = "Nombre de films"
  ) + 
  theme_minimal()
```

Nous observons que beaucoup de notes sont à zéro, cela peut être dû à deux choses :  
1- La note du film est de 0  
2- Le nombre de votes est de zéro, la moyenne est donc automatiquement à zéro. Cela représente `r nrow(filter(clean_movies, vote_average == 0, vote_count == 0))` films sur les `r nrow(filter(clean_movies, vote_average == 0))` qui ont une note de zéro, soit `r (100 * nrow(filter(clean_movies, vote_average == 0, vote_count == 0)) / nrow(filter(clean_movies, vote_average == 0))) %>% round(2)` %.

Nous ne tiendrons donc pas compte de ces films :
```{r clean-votes}
clean_movies = clean_movies %>% filter(vote_count != 0)

ggplot(clean_movies, aes(x = vote_average)) +
  geom_histogram(binwidth = 0.5, fill="steelblue", color="black") +
  labs(
    title = "Distribution des notes moyennes des films",
     x = "Note moyenne",
     y = "Nombre de films"
  ) + 
  theme_minimal()
```
On note qu'une grande partie des film ont une note supérieure à 5 et inférieure à 8. En plus de cela une minorité importante  de film (20 000) recoivent une note parfaite de 10/10.  

-   **Variable `revenue` :**  

```{r movie-revenus}
ggplot(clean_movies, aes(revenue)) +
  geom_histogram(binwidth = 100000000, fill = "skyblue", color = "black") +  # Adjust binwidth as needed
  labs(title = "Revenu généré par les films",
       x = "Revenue (in USD)",
       y = "Nombre de films") +
  theme_minimal()
```

On remarque `r (100 * count(filter(clean_movies, revenue == 0)) / nrow(clean_movies)) %>% round(2)` % des films on un revenue de 0, donc non référencé. Supprimons donc ces films.

```{r movie-revenue-clean}
clean_movies <- clean_movies %>% filter(revenue != 0)
```


```{r movie-revenus-thresholds}

# Définissons 7 seuils de revenu en millions pour avoir une idées de combien de film peuvent atteindre combien de revenue
revenue_thresholds <- c(1, 5, 10, 20, 50, 100, 500) # En millions

# Dataframe pour quantité de film dépassant chaque seuils
revenue_counts <- data.frame(
  Seuil = factor(paste0(revenue_thresholds, "M+"), levels = paste0(revenue_thresholds, "M+")),  # Formater les labels pour affichage graphique
  Nombre_de_films = sapply(revenue_thresholds * 1e6, function(threshold) sum(clean_movies$revenue > threshold, na.rm = TRUE))
)

ggplot(revenue_counts, aes(x = Seuil, y = Nombre_de_films)) +
  geom_bar(stat="identity", fill="steelblue") +
  labs(title="Nombre de films dépassant différents seuils de revenu",
       x="Seuil de revenu (Millions de $)",
       y="Nombre de films") +
  theme_minimal()
```

La première chose que l'on observe c'est que seulement une minorité des films dépassent les 500 millions de revenue. Une nouvelle plus suprenante est qu'environ la moitié des films ont un revenu supérieur à 20 millions de \$.

### D- Rééchantillonnage

Après nettoyage, nous nous retrouvons avec un un dataset de `r nrow(clean_movies)` films.  
Et voici le résumé des variables du dataset après nettoyage :
```{r clean-variables-details}
skim(clean_movies)
```

Pour terminer, nous répartissons notre jeu de données entre l'entraînement et les tests, avec une proportion de 80% :

```{r train-test-split}
train_test_split <- initial_split(clean_movies, prop = 0.8)

train_movies <- training(train_test_split)
test_movies <- testing(train_test_split)
```

## III- Hypothèses statistiques

### A- Hypthèse 1: Films en anglais et revenu

### B- Hypthèse 2: Regroupement naturel des films basé sur `budget`, `revenue`, `popularity`

### C- Hypthèse 3: Popularité et rentabilité

Hypothèses :

H0 : La rentabilité dépend uniquement de la popularité du film.

H1 : La rentabilité dépend davantage d'autres facteurs que de la seule popularité.

```{r train-test-split}
library(tidyverse)
library(randomForest)

df <- clean_movies %>%
  filter(revenue > 0, budget > 0) %>%
  mutate(rentabilite = revenue / budget) %>%
  select(rentabilite, budget, popularity, runtime, vote_average, vote_count) %>%
  na.omit()

set.seed(42)
model_rf_rent <- randomForest(rentabilite ~ ., data = df, importance = TRUE)

importance(model_rf_rent)

```
Le budget est le facteur le plus influent sur le revenu.

La popularité a un impact modéré, moins important que le budget et le vote count.

```{r}
imp <- as.data.frame(importance(model_rf))
imp$Variable <- rownames(imp)

ggplot(imp, aes(x = reorder(Variable, `%IncMSE`), y = `%IncMSE`)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Importance des variables (Random Forest)",
    x = "Variable",
    y = "% d'augmentation de l'erreur MSE"
  ) +
  theme_minimal()

```
L'analyse des importances des variables montre que la popularité n'est pas le facteur principal pour prédire le revenu ; des variables comme le budget et le nombre de votes sont plus déterminantes.
Cela rejette H0 et confirme H1 : la rentabilité ne dépend pas uniquement de la popularité.

### D- Hypthèse 4: La durée d’un film influence sa popularité

Hypothèses :
H0 : La durée d'un film (runtime) n'a pas d'effet significatif sur sa popularité.

H1 : La durée d'un film (runtime) a un effet significatif sur sa popularité.

```{r}
imp <- as.data.frame(importance(model_rf))
imp$Variable <- rownames(imp)

ggplot(imp, aes(x = reorder(Variable, `%IncMSE`), y = `%IncMSE`)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Importance des variables (Random Forest)",
    x = "Variable",
    y = "% d'augmentation de l'erreur MSE"
  ) +
  theme_minimal()

```

La variable runtime a une faible importance dans la Random Forest.

La durée d’un film n’influence pas significativement la popularité.

H0 est supportée : runtime n'est pas un facteur déterminant.

## IV- Modèles de prédiction de la rentabilité 

### A- Analyse en composante principale


```{r}

# Sélection des variables numériques pertinentes et suppression des NA

acp_data <- clean_movies %>%

select(budget, revenue, popularity, runtime, vote_average, vote_count) %>%

drop_na()

# standardisation des données

acp_scaled <- scale(acp_data)

# application de l’ACP

res_pca <- prcomp(acp_scaled, center = TRUE, scale. = TRUE)

# affichage de la variance expliquée

summary(res_pca)

```

Les résultats montrent que la première composante principale (PC1) explique environ 43 % de la variance totale, et que les deux premières composantes combinées (PC1 + PC2) en expliquent environ 60 %.

Cela signifie qu’on peut résumer l’essentiel de l’information présente dans les 6 variables d’origine sur seulement deux dimensions, ce qui est utile pour la visualisation et l’exploration.

```{r}

pca_df <- as.data.frame(res_pca$x)

ggplot(pca_df, aes(x = PC1, y = PC2)) +

geom_point(alpha = 0.3, color = "steelblue") +

labs(title = "Projection des films sur les deux premières composantes",

x = "Composante principale 1 (PC1)",

y = "Composante principale 2 (PC2)") +

theme_minimal()

```

Ce graphique montre la projection des films sur les deux premières composantes principales.

On observe une forme en "nuage" dense qui révèle une grande concentration de films aux caractéristiques similaires (ex. budget et revenu modérés), ainsi que des films plus éloignés (très hauts budgets ou revenus) qui apparaissent sur les bords.

Cela permet d'identifier visuellement des groupes de films similaires selon leurs caractéristiques numériques principales.

### B- Modèle polynomial 

```{r}

# modèle polynomial de degré 2 :

poly_model <- lm(revenue ~ poly(budget, 2), data = train_movies)

# résumé du modèle

summary(poly_model)

```

Le modèle polynomial de degré 2 est significatif (p-value < 2e-16) pour l'ensemble.

Les deux coefficients du polynôme sont également significatifs.

Le R² de 0,5842 montre que ce modèle explique environ 58 % de la variance du revenu à partir du budget, ce qui est une nette amélioration par rapport à une simple régression linéaire.

```{r}

test_movies <- test_movies %>%

mutate(pred_poly_revenue = predict(poly_model, newdata = test_movies))

```

```{r}

ggplot(test_movies, aes(x = budget, y = revenue)) +

geom_point(alpha = 0.3, color = "grey") +

geom_line(aes(y = pred_poly_revenue), color = "red", size = 1.2) +

labs(title = "Modèle polynomial : prédiction du revenu à partir du budget",

x = "Budget",

y = "Revenu prédit") +

theme_minimal()

```

La courbe rouge montre l'ajustement du modèle polynomial sur les données de test.

On observe une relation croissante et courbée : les films à gros budget génèrent en moyenne plus de revenus, mais la relation n’est pas strictement proportionnelle.

Ce modèle permet donc de mieux capter la réalité du phénomène qu’une droite simple.



### C- Modèle d'Arbre et RandomForest

#### 1. Variables pour les modèles: 
```{r movies-df-for-tree}
rentability_group <- function(revenue, budget) {
  if (revenue > 10 * budget) {
    return("HIGH")  # Très rentable
  } else if (revenue > budget) {
    return("MEDIUM")  # Moyen
  } else {
    return("LOSS")  # Non rentable
  }
}

tree_train_movies <- train_movies %>%
  mutate(
    rentability = factor(mapply(rentability_group, revenue, budget)),
    log_budget = log(budget + 1),
    log_vote_count = log(vote_count + 1)
  )

tree_test_movies <- test_movies %>%
  mutate(
    rentability = factor(mapply(rentability_group, revenue, budget)),
    log_budget = log(budget + 1),
    log_vote_count = log(vote_count + 1)
  )

tree_train_movies %>% count(rentability)

```

#### 2. Entraînement d'un Arbre avec Cross Validation:
```{r simple-tree-train}
library(tree)
tree.movies <- tree(
  rentability ~ . - revenue,
  tree_train_movies
)
summary(tree.movies)
```

```{r simple-tree-plot}
plot(tree.movies)
text(tree.movies, pretty = 0)
```

```{r simple-tree-cv}
cv.movies <- cv.tree(tree.movies)
plot(cv.movies$size, cv.movies$dev, type = "b")
```

L'arbre optimal a donc 4 feuilles, nous n'avons donc pas de modification à faire sur cette arbre.  
Calculons sa performance :
```{r accuracy}
tree.pred <- predict(tree.movies, tree_test_movies, type = "class")
confusion_matrix <- table(tree.pred, tree_test_movies$rentability)
tree_accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
confusion_matrix
```

Nous avons donc une précision finale de `r round(tree_accuracy * 100, 2)` % pour ce modèle.

#### 3. Amélioration avec RandomForest :

```{r random-forest}
library(randomForest)
set.seed(1)

forest.movie <- randomForest(rentability ~ . - revenue, data = tree_train_movies, importance = TRUE)
forest.movie
```

```{r forest-plot}
plot(tree.movies)
text(tree.movies, pretty = 0)
```

**Calcule des performances :**
```{r forest-accuracy}
forest.pred <- predict(forest.movie, newdata = tree_test_movies)
plot(forest.pred, tree_test_movies$rentability)
abline(0, 1)

forest_accuracy <- sum(forest.pred == tree_test_movies$rentability) / length(tree_test_movies$rentability)
```

Nous avons donc une précision finale de `r round(forest_accuracy * 100, 2)` % pour ce modèle. Soit une augmentation de `r round((forest_accuracy - tree_accuracy) * 100, 2)` %.


